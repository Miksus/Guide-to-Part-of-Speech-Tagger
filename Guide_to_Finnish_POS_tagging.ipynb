{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> \n",
    "<br> \n",
    "<br> \n",
    "# Finnish Part of Speech Tagger (POS), End to End Guide\n",
    "\n",
    "Date: 20.08.2018\n",
    "<br>Author: Mikael Koli\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction <a class=\"anchor\" id=\"H1\"></a>\n",
    "Couple of months ago I got my hands on a data set of stock news headers. My intention was to test hypothesis from behavioral finance on Finnish stock markets. I thought I could try a machine learning algorithm on the problem but I was not satisfied with the simple bag-of-words approaches. It felt that these models only memorize the occurences of each word and do not really know anything else about these words. I wanted the model at least to know the functions of each word in a sentence, and for this I needed a Part of Speech tagger (POS). I have never been particularly interested in linguistics but suddenly when it was framed as a data problem, I was in.\n",
    "\n",
    "So I started searching if there were any existing POS taggers. Even though the most widely used Natural Language Processing (NLP) library for Python, NLTK, does have extensive support for Finnish (for example stemmer, stopword list and some corpus), there were no Finnish POS taggers nor POS tagged corpus. The most promising lead I found was NLP hackers' tutorial (https://nlpforhackers.io/training-pos-tagger/) which had some awesome code examples in it. I found the list of features and way to extract them interesting, though, I was sceptical how these features would play out on Finnish text. \n",
    "\n",
    "But now when I had general understanding of the model for the job, I still needed some fuel for my tagger: labeled sentences. It turned out that University of Helsinki had some tagged sentences available but the problem was that there were limited amount of documentation available for the data they had. In this guide I will go through my learning process and show you how you can make your own POS tagger from scratch providing all the code you need. Even though the language here is Finnish, the process of building a good tagger should be similar regardless of language. We will also go through how to tweak the tagger and do diagnostics on it.\n",
    "\n",
    "You can freely use the code in this notebook but I would highly appreciate acknowledgement if you do so. You can also find my current version of the project from my Github: https://github.com/Miksus/Syntags\n",
    "\n",
    "In case you are just interested in the project itself, I would suggest to just skip the code blocks or even jump directly to the section [Problem Framing](#H7).\n",
    "\n",
    "\n",
    "## Navigation:\n",
    "* [Introduction](#H1)\n",
    "* [Setup](#H2)\n",
    "* [Hands on with the data](#H3)\n",
    "* [Structuring the data](#H4)\n",
    "* [Analysis of Input](#H5)\n",
    "* [Analysis of Labels](#H6)\n",
    "* [Problem Framing](#H7)\n",
    "* [Modelling](#H8)\n",
    "* [Splitting the data](#H9)\n",
    "* [Transformation and Feature Engineering](#H10)\n",
    "* [Final Evaluation and Conclusion](#H11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup<a class=\"anchor\" id=\"H2\"></a>\n",
    "I use Python 3 with Pandas, Numpy, Matplotlib and Scikit Learn. If you do not have those installed, there are extensive amount of online tutorials how to install them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirements\n",
      "Python version: \t3.5.2 (v3.5.2:4def2a2901a5, Jun 25 2016, 22:18:55) [MSC v.1900 64 bit (AMD64)]\n",
      "Pandas version: \t0.22.0\n",
      "Numpy version:  \t1.15.0\n",
      "Matplotlib version:  \t2.1.0\n",
      "Scikit learn version: \t0.19.2\n"
     ]
    }
   ],
   "source": [
    "# There are some unimportant but\n",
    "# annoying warnings with my current\n",
    "# setup\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import matplotlib\n",
    "print('Requirements')\n",
    "print('Python version: \\t{}'.format(sys.version))\n",
    "print('Pandas version: \\t{}'.format(pd.__version__))\n",
    "print('Numpy version:  \\t{}'.format(np.__version__))\n",
    "print('Matplotlib version:  \\t{}'.format(matplotlib.__version__))\n",
    "print('Scikit learn version: \\t{}'.format(sklearn.__version__))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hands on with the data<a class=\"anchor\" id=\"H3\"></a>\n",
    "The data can be found at University of Helsinki's website: http://www.ling.helsinki.fi/kieliteknologia/tutkimus/treebank/sources/.\n",
    "<br>I used the sample file _ftb3.tgz_ which is about 3.7 gigabytes unpacked. The problem is that the file cannot be be inspected with a text editor so we will inspect it with code. For the sake of simplicity, I have taken the first 20 000 sentences as subsample pretending it to be the complete data. \n",
    "\n",
    "Also, the file extension of the actual file is \"conllx\" but that is just for indicating its structure. The file is in plain text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'ftb3_subsample.conllx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspect_file(filename, n_rows):\n",
    "    \"Return n_rows of the file\"\n",
    "    \n",
    "    cont, n_sents = [], 0\n",
    "    with open(filename, 'r', encoding='utf-8') as f_read:\n",
    "        \n",
    "        for n, row in enumerate(f_read):\n",
    "            cont.append(row)\n",
    "            if n+1 == n_rows:\n",
    "                break\n",
    "                \n",
    "    return '\\n'.join(cont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s><loc file=\"JRC_Acquis Corpus/fi/1958/jrc31958Q1101-fi.xml\" line=\"28,29,30,31,32,33\"/>\n",
      "\n",
      "1\tNEUVOSTO\tneuvosto\tN\tN\tN Nom Sg Cap\t2\tattr\t_\t_\n",
      "\n",
      "2\tEURATOMIN\tEuratom\tN\tN\tN Prop Gen Sg Cap\t3\tattr\t_\t_\n",
      "\n",
      "3\tHANKINTAKESKUKSEN\thankinta#keskus\tN\tN\tN Gen Sg Cap\t4\tattr\t_\t_\n",
      "\n",
      "4\tPERUSSÄÄNTÖ\tperus#sääntö\tN\tN\tN Nom Sg Cap\t7\tattr\t_\t_\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(inspect_file(file, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file's structure might be confusing at first glance. The first row determines the source of the sentence (beginning of a sentence is marked with \"$<s>$\") and the following rows represent words in a sentence. A sentence ends to a line marked with \"$<\\s>$\" and the numbering on the first column starts from beginning. Tab or _\\t_ is the separator of cells.\n",
    "\n",
    "The table would look like this if properly structured:\n",
    "\n",
    "| Word number | Word     | Base word | Part of Speech | Part of Speech | Morphology   | Relation | Function | Empty | Empty |\n",
    "|-------------|----------|-----------|----------------|----------------|--------------|----------|----------|-------|-------|\n",
    "|   1         | NEUVOSTO | neuvosto  | N              | N              | N Nom Sg Cap | 2        | attr     | -     | -     |\n",
    "|   2         | EURATOMIN| Euratom   | N              | N              | Prop Gen Sg Cap| 3      | attr     | -     | -     |\n",
    "|   3         | HANKINTAKESKUKSEN| hankinta#keskus| N | N          | Gen Sg Cap   | 4        | attr     | -     | -     |\n",
    "\n",
    "<br><br>\n",
    "I am unsure what those two last columns represents but they are intentionally left blank by the researchers. Also, for some reason the Part of Speech column seems to be duplicated. My assumption is that the second of the columns is meant to be tags for the base word but I did not find any instances where the values of these columns differ.\n",
    "\n",
    "Short description of the other columns:\n",
    "1. Word number: \n",
    " - the index of the word in the sentence (number 1 is first word of a sentence)\n",
    "2. Word:\t           \n",
    " - the actual word\n",
    "3. Base word:       \n",
    " - base form of the word (components of a combination word are separated with character \"_#_\")\n",
    "4. Part of Speech:  \n",
    " - POS tag of the word (Verb, noun, adjective, conjuction, etc.)\n",
    "5. Morphology\n",
    " - Detailed description of the word's morphological structure\n",
    "6. Relation\n",
    " - Relations of the words in the parse tree\n",
    "7. Function\n",
    " - Function of the word in the sentence (subject, object, main, etc.)\n",
    " \n",
    " \n",
    "Next we go deeper how to read the file for our purpose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structuring the data<a class=\"anchor\" id=\"H4\"></a>\n",
    "First we import pandas for handling the table. We make a similar function as we did before and loop it through to collect the rows and tabulate the data. We also want a column numbering the sentences. We name this as column _Sentence_. \n",
    "\n",
    "In addition, we will remove the last two empty columns and symbol words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def read_ftb_data(filename, n_sentences=1000):\n",
    "    \n",
    "    columns_list = ['Word', 'Base word', 'Part of Speech', 'Part of Speech, base', 'Morphology', 'Relation', 'Function', '', '']\n",
    "    index =['Sentence', '#']\n",
    "    \n",
    "    column_locs = list(range(len(index+columns_list)))\n",
    "    n_sents, cont = 1, []\n",
    "    with open(filename, 'r', encoding='utf-8') as f_read:\n",
    "        for n, row in enumerate(f_read):\n",
    "            if '<s>' in row or len(row) == 0:\n",
    "                # Sentence source informations\n",
    "                # are not our concern\n",
    "                continue\n",
    "            elif '</s>' in row:\n",
    "                # End of sentence\n",
    "                n_sents += 1\n",
    "                if n_sents == n_sentences:\n",
    "                    break\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "            # Splitting the row to list\n",
    "            # Adding the sentence numbering,\n",
    "            # appending to the container\n",
    "            # and removing the unneeded columns.\n",
    "            row = row.replace('\\n', '').split('\\t')\n",
    "            row = [n_sents]+row\n",
    "            row = [row[col] for col in column_locs]\n",
    "            cont.append(row)\n",
    "\n",
    "    df = pd.DataFrame(cont, columns=index+columns_list)\n",
    "    df = df.set_index(index)\n",
    "    \n",
    "    # Removing the empty columns\n",
    "    df = df.drop('', axis=1)\n",
    "    # Selecting rows where Part of Speech is not Punct\n",
    "    df = df[df['Part of Speech'] != 'Punct']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Base word</th>\n",
       "      <th>Part of Speech</th>\n",
       "      <th>Part of Speech, base</th>\n",
       "      <th>Morphology</th>\n",
       "      <th>Relation</th>\n",
       "      <th>Function</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sentence</th>\n",
       "      <th>#</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>1</th>\n",
       "      <td>NEUVOSTO</td>\n",
       "      <td>neuvosto</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N Nom Sg Cap</td>\n",
       "      <td>2</td>\n",
       "      <td>attr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EURATOMIN</td>\n",
       "      <td>Euratom</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N Prop Gen Sg Cap</td>\n",
       "      <td>3</td>\n",
       "      <td>attr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HANKINTAKESKUKSEN</td>\n",
       "      <td>hankinta#keskus</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N Gen Sg Cap</td>\n",
       "      <td>4</td>\n",
       "      <td>attr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PERUSSÄÄNTÖ</td>\n",
       "      <td>perus#sääntö</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N Nom Sg Cap</td>\n",
       "      <td>7</td>\n",
       "      <td>attr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>EUROOPAN</td>\n",
       "      <td>Eurooppa</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N Prop Gen Sg Cap</td>\n",
       "      <td>6</td>\n",
       "      <td>attr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Word        Base word Part of Speech  \\\n",
       "Sentence #                                                      \n",
       "1        1           NEUVOSTO         neuvosto              N   \n",
       "         2          EURATOMIN          Euratom              N   \n",
       "         3  HANKINTAKESKUKSEN  hankinta#keskus              N   \n",
       "         4        PERUSSÄÄNTÖ     perus#sääntö              N   \n",
       "         5           EUROOPAN         Eurooppa              N   \n",
       "\n",
       "           Part of Speech, base         Morphology Relation Function  \n",
       "Sentence #                                                            \n",
       "1        1                    N       N Nom Sg Cap        2     attr  \n",
       "         2                    N  N Prop Gen Sg Cap        3     attr  \n",
       "         3                    N       N Gen Sg Cap        4     attr  \n",
       "         4                    N       N Nom Sg Cap        7     attr  \n",
       "         5                    N  N Prop Gen Sg Cap        6     attr  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = read_ftb_data(file, 1000000)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Our data looks as we wanted. We can conveniently select a sentence using Pandas' \"loc\" attribute. Let's inspect another sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Base word</th>\n",
       "      <th>Part of Speech</th>\n",
       "      <th>Part of Speech, base</th>\n",
       "      <th>Morphology</th>\n",
       "      <th>Relation</th>\n",
       "      <th>Function</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hankintakeskukseen</td>\n",
       "      <td>hankinta#keskus</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N Ill Sg Cap</td>\n",
       "      <td>2</td>\n",
       "      <td>advl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sovelletaan</td>\n",
       "      <td>soveltaa</td>\n",
       "      <td>V</td>\n",
       "      <td>V</td>\n",
       "      <td>V Prs Pass Pe4</td>\n",
       "      <td>0</td>\n",
       "      <td>main</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>perustamissopimuksen</td>\n",
       "      <td>perustamis#sopimus</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N Gen Sg</td>\n",
       "      <td>7</td>\n",
       "      <td>subj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ja</td>\n",
       "      <td>ja</td>\n",
       "      <td>CC</td>\n",
       "      <td>CC</td>\n",
       "      <td>CC</td>\n",
       "      <td>6</td>\n",
       "      <td>phrm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tämän</td>\n",
       "      <td>tämä</td>\n",
       "      <td>Pron</td>\n",
       "      <td>Pron</td>\n",
       "      <td>Pron Dem Gen Sg</td>\n",
       "      <td>6</td>\n",
       "      <td>attr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>perussäännön</td>\n",
       "      <td>perus#sääntö</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N Gen Sg</td>\n",
       "      <td>3</td>\n",
       "      <td>conjunct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>määräyksiä</td>\n",
       "      <td>määräys</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N Par Pl DV-US</td>\n",
       "      <td>2</td>\n",
       "      <td>obj</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Word           Base word Part of Speech  \\\n",
       "#                                                            \n",
       "1    Hankintakeskukseen     hankinta#keskus              N   \n",
       "2           sovelletaan            soveltaa              V   \n",
       "3  perustamissopimuksen  perustamis#sopimus              N   \n",
       "4                    ja                  ja             CC   \n",
       "5                 tämän                tämä           Pron   \n",
       "6          perussäännön        perus#sääntö              N   \n",
       "7            määräyksiä             määräys              N   \n",
       "\n",
       "  Part of Speech, base       Morphology Relation  Function  \n",
       "#                                                           \n",
       "1                    N     N Ill Sg Cap        2      advl  \n",
       "2                    V   V Prs Pass Pe4        0      main  \n",
       "3                    N         N Gen Sg        7      subj  \n",
       "4                   CC               CC        6      phrm  \n",
       "5                 Pron  Pron Dem Gen Sg        6      attr  \n",
       "6                    N         N Gen Sg        3  conjunct  \n",
       "7                    N   N Par Pl DV-US        2       obj  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we know the basic structure of the data we have and next we take a closer look what values the data has. We are particularly interested in columns _Word_ and _Part of Speech_. The first one will be our input feature and the latter our output feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of Input<a class=\"anchor\" id=\"H5\"></a>\n",
    "\n",
    "Next we inspect the top 10 most frequent words in our data. This can be done using Pandas' value_counts method with integer location (iloc). Then we divide the value counts with count of all of the words so we get a ratio of each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ja          0.030603\n",
       "on          0.027023\n",
       "tai         0.014947\n",
       "1           0.012485\n",
       "2           0.009101\n",
       "artiklan    0.007672\n",
       "artikla     0.007018\n",
       "ei          0.006259\n",
       "että        0.005904\n",
       "3           0.005648\n",
       "Name: Word, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Word'].value_counts().iloc[:10] / df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The source text is seemingly about legislation as the word \"artikla\" (article) is in two forms on the top 10 most frequent words. The other most frequent words are not as surprising: \"ja\" (and), \"on\" (be/is), \"tai\" (or) and then some numbering with correct order. We might want to remove the numbers as we did with punctuations as numbers can easily be tagged with regular expressions. For this tutorial, we will keep them though.\n",
    "\n",
    "Next we will take a look at our explained variable, Part of speech tags."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of Labels<a class=\"anchor\" id=\"H6\"></a>\n",
    "The part of speech tags are not really self explanatory. Fortunately there is an extensive manual for the tags.\n",
    "\n",
    "Here is a list of the tags:\n",
    "- N: Noun\n",
    "- V: Verb\n",
    "- Num: Number\n",
    "- Pron: Pronoun\n",
    "- A: Adjective\n",
    "- CC: Coordinating Conjunction\n",
    "- PrsPrc: Present Particle\n",
    "- PrfPrc: Past Particle\n",
    "- AgPrc: Agent Particle\n",
    "- Adv: Adverb\n",
    "- CS: Subordinating Conjunction\n",
    "- Abbr: Abbreviation\n",
    "- Interj: Interjection\n",
    "- NON-TLOW: The manual actually says nothing about theses\n",
    "\n",
    "If you like to know the tags more in detail, I recommend reading the manual found with the treebank file: http://www.ling.helsinki.fi/kieliteknologia/tutkimus/treebank/sources/FinnTreeBankManual.pdf\n",
    "\n",
    "But next we will inspect the frequency ratios of each tag to understand the distribution of the our labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "N           0.429347\n",
       "V           0.126547\n",
       "Num         0.096863\n",
       "Pron        0.066738\n",
       "A           0.066550\n",
       "CC          0.051028\n",
       "PrfPrc      0.037219\n",
       "Adv         0.033300\n",
       "PrsPrc      0.029489\n",
       "Adp         0.021452\n",
       "CS          0.019817\n",
       "NON-TWOL    0.015222\n",
       "AgPcp       0.003623\n",
       "Abbr        0.002755\n",
       "Interj      0.000051\n",
       "Name: Part of Speech, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Part of Speech'].value_counts() / df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As one could expect, Nouns are the most frequent (43% of all words), followed by verbs (13%) and numbers (10%). If you are familiar with Penn treebank you might realize these tags are somewhat different. You could combine this column with the column _Morphology_ to gain similar tags. Fitting an algorithm with the column _Morphology_ as your labels could easily kill the performance of your model as the column can have over 5 000 different values. For the sake of this tutorial, we will use _Part of Speech_ column as our label feature. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Framing<a class=\"anchor\" id=\"H7\"></a>\n",
    "Applying a Machine Learning algorithm directly to the words is not a wise idea. A machine can only tell if two words are exactly identical or not. Making the model memorizing all of the word we have is not really efficient thus we need some feature engineering.\n",
    "\n",
    "Characteristics like the previous word, the next word, the position of the word in the sentence, capitalization, suffixes and prefixes can influence on what tag a word should have. Think about the following example:\n",
    "\n",
    "_I wonder if Patt is making the report._\n",
    "\n",
    " \n",
    "_Wonder_ is a noun but also a verb. In this case it is obviously a verb because the word \"I\" is before it and the word \"if\" is after it. Also, we know that words that ends in _-ing_ are most likely verb with some exceptions (ie. king). Capitalized words are very likely nouns, especially if they are not in the beginning of a sentence. One could construct similar rules also for Finnish words."
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2MAAACGCAYAAABQUFKlAAAgAElEQVR4Ae2dbWwdVZrn/8Tmrgm2GSEcZ2KHCA+tsZ29CHlaidy03ETE6YjNF1ilQ6NOKwQ0g4hA6Q9R9/SHhOTD0qtotyMQvT0rXqLOCBKQhpU2YtMkUWirW1FYTQZxF8ezYtJjsLNxglhhuyF7sZPVU1Xn3qq6datO1a1T917nHwluvZzX3/lX+XnqvN1y48aNG+A/EiABEiABEiABEiABEiABEiCBTAksyzQ3ZkYCJEACJEACJEACJEACJEACJGARoDNGIZAACZAACZAACZAACZAACZBAHQjQGasDdGZJAiRAAiRAAiRAAiRAAiRAAnTGqAESIAESIAESIAESIAESIAESqAMBOmN1gM4sSYAESIAESIAESIAESIAESIDOGDVAAiRAAiRAAiRAAiRAAiRAAnUgQGesDtCZJQmQAAmQAAmQAAmQAAmQAAnQGaMGSIAESIAESIAESIAESIAESKAOBOiM1QE6syQBEiABEiABEiABEiABEiABOmPUAAmQAAmQAAmQAAmQAAmQAAnUgQCdsTpAZ5YkQAIkQAIkQAIkQAIkQAIkQGeMGiABEiABEiABEiABEiABEiCBOhCgM1YH6MySBEiABEiABEiABEiABEiABOiMUQMkQAIkQAIkQAIkQAIkQAIkUAcCdMbqAJ1ZkgAJkAAJkAAJkAAJkAAJkACdMWqABEiABEiABEiABEiABEiABOpAgM5YHaAzSxIgARIgARIgARIgARIgARKgM0YNkAAJkAAJkAAJkAAJkAAJkEAdCNAZqwN0ZkkCJEACJEACJEACJEACJEACdMaoARIgARIgARIgARIgARIgARKoAwE6Y3WAzixJgARIgARIgARIgARIgARIgM4YNUACJEACJEACJEACJEACJEACdSBAZ6wO0JklCZAACZAACZAACZAACZAACdAZowZIgARIgARIgARIgARIgARIoA4E6IzVATqzJAESIAESIAESIAESIAESIAE6Y9QACZAACZAACZAACZAACZAACdSBAJ2xOkBnliRAAiRAAiRAAiRAAiRAAiRAZ4waIAESIAESIAESIAESIAESIIE6EKAzVgfozJIESIAESIAESIAESIAESIAE6IxRAyRAAiRAAiRAAiRAAiRAAiRQBwKtQXkuXv5nzL7217hxbS7oNq+RQCwCt234G8h/af6jRtOkeXOnZUKfQpQavbl1lWbtTWh0+st/wctjP8XX38ynWVSmdZMS2DzwI3x/4Eep1p4aTRXnTZ2YCX2mCbTl+eeff96f4LL2u5D71ndQLLwHLBT9t3lOArEILPzrP1rhb73n27HihQWmRsPo8F4cAib0KflTo3FagWHDCJjQaGfbnehf+Vf4p6kxLFzn3/kw/rwXTeCTzz/CLQDu7bovOrBmCGpUExSDRRIwoc/ITGMECHTGJD4NiRgUGTSSgAljghqNxM4AmgRM6FOypkY1G4DBIgmY0CiN3UjsDBCDgAmDlxqN0QAMGkrAhD5DM4xxs6ozJmnQkIhBkkEjCZgwJqjRSOwMoEnAhD4la2pUswEYLJKACY3S2I3EzgAxCJgweKnRGA3AoKEETOgzNEPNm6HOmKRBQ0KTJINpETBhTFCjWugZSIOACX1KttSoBnwG0SJgQqM0drXQM5AmARMGLzWqCZ/BIgmY0GdkphEBIp0xiU9DIoIib8ciYMKYoEZjNQEDhxAwoU/JjhoNgc5bsQiY0CiN3VhNwMARBEwYvNRoBHTe1iZgQp/amQcE1HLGJB4NiQB6vJSYgAljghpN3ByM6CNgQp+SBTXqA83TxARMaJTGbuLmYMQAAiYMXmo0ADQvJSJgQp+JCgJA2xmTDGhIJMXMeEEETBgT1GgQaV5LQsCEPqUc1GiS1mCcIAImNEpjN4g0ryUlYMLgpUaTtgbj+QmY0Kc/D53zWM6YJEhDQgcrw+gSMGFMUKO69BkuioAJfUqe1GgUed7XJWBCozR2dekznA4BEwYvNapDnmF0CJjQp06+7jCxnTGJTEPCjZDHtRIwYUxQo7W2CuMrAib0KWlTo4owf2slYEKjNHZrbRXGdxMwYfBSo27CPK6FgAl9xilPImdMMqAhEQczw0YRMGFMUKNR1Hlfl4AJfUre1KhuCzBcFAETGqWxG0Wd9+MQMGHwUqNxWoBhwwiY0GdYfu57iZ0xSYSGhBslj2slYMKYoEZrbRXGVwRM6FPSpkYVYf7WSsCERmns1toqjO8mYMLgpUbdhHlcCwET+tQpT03OmGRAQ0IHM8PoEjBhTFCjuvQZLoqACX1KntRoFHne1yVgQqM0dnXpM5wOARMGLzWqQ55hdAiY0GdUvjU7Y5IBDYkozLwfh4AJY4IajdMCDBtGwIQ+JT9qNIw678UhYEKjNHbjtADDRhEwYfBSo1HUeV+XgAl9huWdijMmGdCQCMOc8F73c7jjp/8Ft//bf4NvPjiH6wmTacZoJowJarQOSlAa7p7G1//rf9ehAGayNKFPKemS12ij6qFRy1WDfE1olMZuDQ1iMmpnH1b9v/+LOZN5GEjbhMFLjYY0VD100vkEfvbvfoF/3/l/8NvpP4YUrvFumdBntVq2VruR5HrLyr9E587/itnX/ho3rtX5tZA/hDu3jgBXD2P2pRexEFCh1o3voHNkjV6Y8b344ujxgFR4yRSBr8/8nZX0bRv+JrUsGkqjqdWqnFBJ0wCKbw9hvlC+x6N0CZjQp5Sw+TS6Be0HDiBXFe8Y5vfuRrHqfd4wRcCERnvu+AvsGvmPeHnsp/j6m3lTRddKd9XgK9jT3wtMH8RPzp0OidOHh0d/hdGOKZw89RTenQ0J2my3evfhl+uGAZzFkX/Yj/NNVv4TF/7eKvH3B36UWskbSaN2pZT+9Ko4M/EMfjF+US+wbqgm14luNdMOZ0KfQWVcFnSxlmvKkLilraOWZGqPWzhl//Hv2oBcd1By/cgNrLFvdPWhGohld9lhih8vBUesH8ufPY87D7yD5YFMgjjV95oYE8qgSKskDaPRtCpUSselaQC5tVtKd3hghoAJfUpJm1ajVyexWPFfykaF1ZRx32Vxw5vRSz1SNaFRZezedmt7PapUyvPS1B8wI2c938VQ6WrAQef3cJ+YJHN/wIdGHTExuk/gl4++goc7A8ph8tLcp7hsMn2DaYvB+1vHKUsrm0bRqKrP5dkpzMy5/1N34Ls+hSsmNZq6Tuqo+TJCo0cm9OkvcKo9YypxZUjUt4fsOIrjB5AbXINb8/3AzIQqnvN7L5Z1qUsjyOWBYkUvwhbkBiXMWMA9FZe/pgkoZ4w9ZBGkuzfhVtH0+BiKgyPIDW5EDsfZIxGBrdbbJvQpZWqM92gcOmOYf4k9YHGIZRXWhEaVsVvXHrLZ3+GjuW0Y7RjG/b3A+algoqt6H4B8f5yZ/h0uBQdp3qtT+/GTKvVupkqZ6IFoCI1ajXAR58895e21lOF7G7ehe+4YfnPydfO6XCI6qZemTejTXZdqHULuMImOlSFRzx6y4sdjVtlb7rq3sg55MVRhfcWVm4G9CN19aJGbVy/eVPO1KmHV/4qJr7uNoNE0ybbmN1h6LX68G8VxSdn+yJBmHkwrmIAJfUpOS02jwfR4NQsCJjSqjN369ZBdxIfTtieS73moCsY+3N/TC2AKH02Z6KWtki0vxyZgogei/hqNjYERGpSACX2qqhrpGVOJK0Oibj1kVy5iESNoCeghaO2W4YeT+Ob9M8DWHWjp6oPAcM8tU8bt4oX3fNefQ9uDG5DrcoY5Wk7dGL5+azeK1pgJRQCATAzftQMYexxfFjah/Qc7kJPei6uHMf/Si06vRT9yG5/GbSMjtvOHSSyOvYo/VfTUldNtzUsZnLSsy5NYHH8Vfzp63FNWFSP32Hm0W718cmUN2nadR5tz0z+3yE5bs34qgwx+TXzdrbtGU+OmhijavbhFjAHSO/bgc2gtBMyZdOvyFLD8sRfQNqj0PIni23+L+YKvNzlJnID6qXlti/JMnPLlASDqfkCSDXHJhD6lYktHoxHN1N2P3IYXcNvgGuc9KB/LxvDNW7vxleu9GuddJjnGDQ/0e5+Hq2O45iuDuyZB7+Li2Ku4dir4XeyOm/WxCY0qY7dePWTWUMX+bei2hiqe9vY+COCQIYqrep/A5oFtyJdmVUyhMPEmToyfDuypWNW7Dz8eGEa3Cj83hcK0HX7l+hPY3qNatBejG09g1DktfLAZr7l6r+x8H0C+Q5xE+9/M3Fm8d24/zvuHqDk9KJB5RFPfw871TnnnjuHIyddxXvWweObNhc1R8s6bi8tAldfUr4keiHprNBGrqHaXRDv7MDTwc2zq6bV6fuWS6Oijc/sr50UG6kTSsHvobH3dg4cHfohR6+OFDOs9i5NBaTkVGoqheTtKHx5e/3Pt9BtNm1IHE/qUdI31jDltVTIk6tJDNvMevrkqJVmDVs8cKWW4TmKh4ISpmFtWDvONyyi1DMWt4gStwaIMB5P/rgItXSNo33Ue7XlVc9/vXU9bTpk4YotSpq6+UoDcY2+g3XLEJsvpjRxA564dJaOkFFgO8ofQaZVBHDB3GcppesIDuP7xYSvtRedGKd74YRSvlEMnrl85CaNHJr7uKmO3LhpNi1b+abRZQxSduZKFX+OapbNqcyadjEWXB95A2yAcLU1az0tu6xu4Y2N/cOmSxHGltFA4A9Fhy8Am6wOI6xbEELbnck7C/dx5wzTumQl9Sm2XhEbDmi0vH63eQLt8ELiq3mmT1nu1bZd3jqvuu0xlFyt815Ol58F+t08CXSPwl0GlXX5flt/Fi1iDnLy/n30uQN8qZv1+TWhUGbt16SGzhioKT3uoop+sGqJYuOAdCmYt/rFOHJspzEyfRWH6LGbQi3z/HuwZfQKrfAmJ4blnnThirvAddvjNvcDl6WNOGnZElWZh+phnnlo5395SvoU5oLtjGNs3nsDOsn/mLUHHdmtYmziOM7I+Wsfd3vueM+kxtOsk9bL/m7Ln17nClcviqlMIA1dUo4cmeiDqqtFaaFVr915xon6F7eI4zTltPDdl6Wh0Y4I5i1Y+ezDaA1svc1NAxzDC0tLVvFX9zh/iZ4/+Sjv9RtWm1MWEPo32jCn9KUMi+x6yCRQvTKKtyz9vzJkvNi6G6wSuh4W5eqbc2yVOkKy+iDHMv+ztBWu1HKQR5LYeQq5QOW+iZbDKyo75Q06PlW/Fse4taN8VtEJZP5Y/OGL16l17+RHPF2PFO+h3ofAi5gsyiX0ELV2T+OaM92uzFaeG+gXlaeqaia+79dNoOpRyax1NnFELzVTTvjc/S5fjezHr7lF1ViJtGXkauVNVtBwzjidX6yOJ9EbvQFtedOm6W3IqX9XWtit2Qxya0KdUrPE1uga3PXaoclXFj39d2cta0VJ9wPhhzJ95sfy+dfWStm3Ygq+c1Wy13mWu9GOF71qDFp+2VU+tuwxW8t3P4fbA1Xj7YX1gGwzQt6tc9Tw0oVFl7GbfQ2YPVRzt74U1VHHKvariQ9gsqy3iLD509UxJb8CP5frcMRz0zNfpw9B6MXC3YXPv6+XerN59dq/X3FkcOeldsVC+3q+cBS7NSnjpkRq2Vm386EJA70TvPnv1R1n58JS3F0x63cTZy6/bh6Epbx6ile6e4YDyVlfRpfH9eM112zJu5Xz6TbvXJC4DV1pZHJrogaifRpMTq97udwPTx3Dkwuue3lSrnft7MTrwEN4NXWHUWyYrn+mDOHiu3CscldalKQ3Nq2w6etGtm36Da1OqlLY+jfeMqXZQhkTWvQ+BX+HVfLHPP7GKVwrjnlvmhJH5Ymroom3wypLhXkdMElko7MZ86DwdmdxeOVxMpbk49mvvQgszxzH/8mGrB0ExNP2rypKsfqZL503fxNfdemnUW7MkZ85CM+4PB5Ymw3qgnHxk6we3IyaXVa9atTlnSeJ4qmU7inLJP1ezpMEmX73UhD6FV2NrdA3Euc/5/1sbMGfXowfR3G58edTriEkQ9W72Bzd2HqDtUhmcoewq79wGe+RC8X3/e30CxTP2u9uvbxW3EX5NaFQZu1n3kF0afxPWNx3/qoq934U1WGX6957hi0MD26xhXf7eMuAizl84ZvUgueegDYkjJDK9UOkkiUFaMbSwSgOX0vnA64hJ8EtT+3FkWo6Ce/ispes9jmOVTIIuK+NWnEDHQI/LIChZ09dM9EDUS6PJWckHAG+vrpXW1H784lyl9korjMbNUD5MuBwxiV5Kq/Puip7iuMlbHz40028GbUr909RnJj1jqtGUIZFpD9mMzBuTYYTl5ettg881DEqFcc0ts+eUAeUl7fvRaq2+OInrrmF9qm7ye/1ze4hXS3c/4BraaIWxeuHcoeW4nKb+kKwJfPX+GNq22kNnbpV5YmeOY8E1p8Kfi955uSyJ6qeXSaqhTHzdrYtGa6WiPi745jYirAdK5en62KAuARNYsIY4AoFaThKnnLh1tHDqVRRHZLVT94qPS2v1UhP6FHiNq1Ff776vzbVOZd7Yik3IrVVDrsvzx7Ti1xooSNvq74MnbfW+BFrWHkL7Ws9Na6ivtfhTwFxkf8h6npvQqDJ2s+0hO40Pp/cg3+NdVbHk/Ey7e8v6sNJZdn5Fzz7sLM3zUi2x2p5/4xigl6DCT+Gyfz6XiqL1G53OZRkahl6s6BT9+xYb8TmUWllagWSejuN8ihPoXIvHQD+3tEOm3QMh5auPRhOSiWp3mTfW+T3c36OGrTr6jZvd7KeV8yRnP4WYu55ZPnHTVeG101fPCaD3fKoM6vOblj4zdcYEVfaGhFriXi1f7/wR9fQiVIax5624l7RXS+FPRjo+9uqNlQsTpCaVwm7MwlnAY/AAOgcPWPMs5oMWENHOtIHqp11mlPYgu5mXvVe9SRh4Gu13BcOzvtAX1BDG4DDuq+rDgvta1HG8OP5nTuZC2iucIvDDRVTujXnfhLErNc3+PWqar2/RDNPZpZi+9AZajleKaWaZlAmN1sPYPT99Ftt7hl1DFR/C/Zaj5Rui6IIrQ7OiDc17sNJasOOzGp0x/XS6O+6pdMZc5Y512Lsdo1L+6YPlYZeuBPQYuCLU4TAtg9dd9Hpo1J1/7ce+xTBqT7DhUmgGbQq0NPSZuTMmBc/akLCWuJehM7IJ7pU+Zy+m8vBDKZMKY/UEXFH7NTmLIVgS/QTXrd4CezGQilUTrTD2/xad4Y+uS6kf2vMgXgScFcjaB2UBkXcQZx6Zt1CNVT9v2cLPTBgTWWs0vIYhd7ufw23OKpmyiEyL1XsbEN7TAxVw33dJbXbuuxx6GjeOeuaUo6icynJvdGh2TXPThD6l8k2jUY2WkjlWsoiMtcrsW67his4Kno3r7EzW8M7VAJNREBMazdzYnfo9CjLnSq2qWGWIYhmpd1XB8nX/0R9xeQ7Id6y2e9QS947ppzMz90d/IRKeP4Sd62SIZXl4ojchXQbeWPU4S8Pg9Zc7c436C1DDucxtlMU2ZPjfEfdwRbVqYg1pN0bU5tGm8KpVn5nNGfM3rjIkMplDVnCcqq4+5FbYe4dVGHzWMvjOCm+BYZyhW1iDZSv8tZFztQocsFixwXRQeLkWlWa1eK7rMxMoHn0Es2P2EMngsrnCVz2MKkuS+lXNLPUbYkwogyKtxDPVaMJCl7ZfGHscX+wdCvjvcXtVxWrzvwLzLQ/B0tdygjjqubQcRTXv7TCuuRf0CCxf8100oU+h0AwajW4tpZ1JXHM7YtER6xgi6n1Zx6IlzNqERpWxm80cMhmqKJUfxqbBPgQPUZT7F50ert7ScMVwZHHDV0stKh21HxpwZdY3RLFakhHXh9bvsebMFUrDE1WEqLKocI31Kwbvby/8faqFylajaRVdDeWbwkm3I5ZW8nVNpzm1Kchq0WfdnDEpeHaGhOr12YDbnJUIK+ZFqWXwuzbg9iph1CbS1oqJvrENrWoVuKvxjMlSmrIflPsBqPpFeAvanz2EnC9/vV6JcAOiVBZZEdKXftL6uatk+tiEMZGdRpPQUQ6ya/5jRTLVF8uwgg4ewJ2PbfFoL7Ktk8SpKJdcOI5r1keEEdz27JP2Juz+eW+B8Zrzogl9ConG1mgtbSX7jlXZ3iP2h6zwd1+SUpbel/53t5OY7D/mf48mySfLOCY0mqWxK0MV5V93z3Z7iOLcMZxwr6LowFTh8gOVS9hLEFkhcciZVybn9lwuICj8qt6HXGHDDclSvrJioit9O09nOGGVMjtF1/9RK0BWGZ5YKosmA/2MzYasxeCtVrIsNVqtDOlcl33H7PmB6aSnk0q45nVS8IdpVm1KPZLq02P/+4Fkca4MCbOLepSX+baGcXnmi6laaoSRFRPXyubJ9p5isleXtW9X14i9kTPsL7tq9UWVcuivrFz34Ajaunag88AGFMdlX5s19obSst+O9Gj4E3D2NJMNUe09y5z8NRxBNa8nt/UdtK+188L7j9jLi5uon7/shs/FmJB/N8Ucsm5nOG2gnsugy4tlPInl3ce9S8ZfncSizDs88KRXezJ0t2KVOCfNJHHKxfEcWSvVjcgy984m7P6Fbzyhm//EhD6FSjbvUVP8y+9e2c/r1vFJyF5dLa7Nn4NyDn2XBUSIGz4gCe+l0vtS3t07rA2qrfex7DPmbKBefNs15NIbu2HPTGhUGbvGF/VQQxU7hq0eoZnp31UuSiDkZeXCHtmkeRv2PLrN2ij3ijX8cDXyzoa3hQ/KK9VdGv8PONnzK4x2SPgHMDP9mbWwwQpnzlnhg9OlFRXVIhz5da9gZ89nQOdq4MJT9nytUr72nmKbps9a6aBz2Nl42u7puFSzOvrw8IC9AuQMvoud67/rSfHy9H68WyqLHgNPAnU+EYNX/n1/4EeplSQzjaZS4vJ2DrIP2H2WHldjhWvz51Sy0UwkVPOaaXiCNbE2pR5J9FnXnjEFXxkSJocslpYnBrB4wTtfTJVjYcZeClzOF6t8oS8eHcLs27YTVFrGuUs2/DyM+Rj7fqk8ZajiVy89jnlxwqw/4rZjVZRhZy/9GtfLAZ0jWfJ+L66N2xuiWstIW/nvxWzA0vn+6AunHvHl5V0dMv36+Utg/tzE190sNBqXTGmIYhWtltOTxTLkzNlvr3wDuPoqvnx5r7Vxua0le9Pd+ZeHvPt/1RrHHd99rHqk5VqEU+mO1szHJvQpPBpRo7rtJO+l2TH5uKWWx1c63Ovd8sOVYNS7zBXUOowb3h8/6NzzvpSPctay/rAcs/mXH6/+DAUl1kDXTGhUGbtmhyyexokJ1RU2hY+mqg/3O39uMw5+cNbaQFk2XJaVGPM9sqGy7AH2jG+xi4t49+QzODJhbwwtCwtI+O65KRQmDnp63y6NP4Uj0/aqiFaaHd6FPzz5OunYG08fw5FTT9l7gNWsBbVYiL0/mV03Vcdh3Get1gh4yhLJoOZCpZpA0h6IsEJko9GwEujfE50d9OjR3vz5yKmD9jYP+knVHDJK80kyaGZtSn3j6vOWGzdu3EgCykScxcv/DLM9ZCZKzTQblYD0jqXZQyb1XDIaVcNgx/fiC2cz3ch2TBInMlEg95j0Nsv+fSEOoEY6zRbEhD6FwZLRaLM16BIsrwmNTn/5LzDeQ7YE24JVCiaweeBHqfaQSS7UaDBrXo1PQFefDdEzpqrXzF92VR342zgETHzdpUbTbt+ltbdYHDom9Cn5U6NxWoFhwwiY0Ggz9T6EseG9xiAQtwdCp9TUqA4lhtEhoKvPhnLGpGI0JHSal2F0CZgwJqhRXfrR4Vo32gt3LKW9xaJrXQ5hQp+SOjVaZsyj2giY0CiN3drahLG9BHQNXm+s8DNqNJwP7+oT0NFnwzljUj0aEvqNzJDRBEwYE9RoNPfoEOXVIK+d0d+QOjrd5gphQp9CgBptLh00cmlNaJTGbiO3ePOVTcfgjVsrajQuMYavRiBKnw01Z8xfCc598BPheS0ETMx/oEZraRHGdRMwoU9Jnxp1U+ZxLQRMaJTzc2ppEcb1E9Cdo+OPF3ZOjYbR4b04BKrps+X5559/Pk5CWYZd1n4Xct/6DoqF94CFYpZZM68lSGDhX//RqtWt93w7tdpRo6mhvOkTMqFPgUqN3vTSSg2ACY12tt2J/pV/hX+aGsPCdf6dT62xbtKEPvn8I9wC4N6u+1IjQI2mhvKmT6iaPhvaGZNWE0OitTeP4of//aZvRAKonYAYE8v+7M/R+ud/WXtiTgrUaGoob/qETOhToFKjN720UgNgQqNi7K65sx//89OTqZWTCd28BMTgvXN5N3r+7C9Sg0CNpobypk8oSJ8NOWfM3VI3rs3hq//xn9yXeEwCiQnc+q3vIJffnDh+UERqNIgKryUhYEKfUg5qNElrME4QARMa/fqbefy3j/4uKDteI4HYBPq7v42h1Q/GjhcWgRoNo8N7cQgE6bOhnTExIGTfMZnzwH8kUCsBMSLaf/ifcUtrrtakSvGp0RIKHtRIwIQ+pUjUaI0Nw+glAiY0Kkau7Dsm83L4jwRqJSCG7pPD+9C67NZakyrFp0ZLKHhQI4Fq+mxYZ4wGRI0tzugeAiaMCGrUg5gnNRAwoU8pDjVaQ6MwqoeACY3SyPUg5kmNBKoZurUkS43WQo9x3QTC9NmQzhgNCHfz8bhWAiaMCGq01lZx4nf3ozWlpJo1GRP6FBbUaLMqovHKbUKjWRi5q3r34WePnsAvrf9ewc7evsaDyxKlQiDM0E2aQRYaTVq2usbrfMJ+rkafwKpaCqLSWf9QLak0RdwofTacHUQDoil01TSFNGFEUKMpNX/+EO7cOgJgDPN7d+NmXEfNhD6ldajRlDTKZGBCo5kYuZ1P4MfrhtGNKcxMf4YrWI0VnWzQpUggytBNUudMNJqkYIzTdAR09NlQztjSMSD6sfzZN9DWNYlrLz+Cr2aaTjtLosAmjIjG1Gij6k2zXFcv4vqSUFy8SpjQp5SgMQMy2RIAABeKSURBVDUaj40dWlM/SZJmHC0CJjSalZG7qvcBdAMofPAUXpvSqm4Kgfrw8OivMNoxhZOnnsK7sykkySRCCegYuqEJBNzMSqMBWfPSEiOgq8+GccaWjgGxxJTUpNUxYURQoymLobAbXxRSTrNJkjOhT6k6NdokAmiCYprQaJZG7sqO3iagzCLWQkDX0I2TR5YajVMuhm0+AnH02RBzxmhANJ/IGrnEJowIarSRW7y5ymZCn0KAGm0uHTRyaU1olEZuI7d485UtjqGrWztqVJcUw0URiKvPuveMpW1AtOafQ9uDO5DrUqgmsTj+Kv509DgW1CUAQeGKY6/i2ilvOHQ/hzt27QDGHseXhXuxfMOTaBtcY6d0dQzX3trtGYaYe+w82gdVRmvQtus82pzT4ttDmHf1BJgqg8pdflvzh3D7gyNoUTyuTqJ4obKe2mWpwi6IsbscWR2bMCKy0GiF9hzdtQTNp1Jzrcb3Yh4HovXm0fAmtP/AeT6uHsb8Sy/ac7W6+5Hb8AJuG1yDFqexFq+O4Rufvt3tGKatZTrPgarj+F58cfS4O2nr2NbkBuS6nOcNgJTp67d2o+gf+uupY/RzWpFZRhdM6FOKnoVGg55x7fdGzPbhezQjQQZkY0KjWRq5qwZfwZ7+cq9Yft0J/HKdVPQsjvzDfpwHsKr3CWwe2IZ8hwIwhcLEmzgxfhqX1CX129mHoYGfY1NPrzXsUS7PzJ3FR+f2e4YhDq0/ge09KlIvRjeewKhzWvhgsz1UsncffrluGJg+iJ+cO60C27+ymMHGbeieO4aDJ18vl8O5joln8Iup72Hneqfcc8dw5OTrVn0kgTh1Cgo7M/0mfnMuoP7eUjbEWVxDV6fQWWpUpzzwtPs9eHjghxjtcXQ9dxZHzu3HeRkG2/kQdq7fU9LyzPQx/OacSz+uzOx2fwB5V6+xaPk9lZYrrH3Yh6HB7djUL3Mv5d8UZibexG8ihv0G6avq81WRZ/NfSKLPujpjaRsQyB9Cp7UggDhgk1iUNu1ag1yXdwWl1o3voHNEDLxyuJbBEeRGDiA30IfZl170OG6WNO56GnfsGkELJlEcH3PSHUHbrncA17yw6x8fRhF9kPTEqF0cH7PLgYsoXimLzGQZVC5lg8ZXz64DwMzxkmMYqyyajFUZsvw1YUSkrVFt1jMv4uvxHWgfHEH7Y1tczsoWtKtFL44ex/V8n5berHYoaVicGqBFPRf553DH1h22Xq+OoXhVPTcjaPHpW7VnlLauaT4HKj3/b5mT6xnqGkGuawTtu87D/2GjFL9Ux/DntBQ+wwMT+pTip61Rvke9oojSuvrAVtas730b9HelQd+jJjSatZF7afYPKEzfjRWdw+jusB2nK9bcrd/jsjgtJWdNLewBrOgZRr5/D/I9d3sdod4n8LN12yxDVIzWgmX8rka+YxijG18BXPPCLk8fQwF3W2mJ4TozfRb2n/xP8WEac8c6tuNnG22jeGYO6O64uyTUeHXahz3iEJYWNhGDfjXyneX0Sgk34EESQzeqGllrNKo8nvuldp9CYfos0Dls6W/7xn1YOQGM9g8Dc3LvM1vzPduwZxReHXt079JmKa0TuF99MHBlPrT+V84HBjt9Syf9e7Cn3xXIdxhLi764S+E0qT7r5oylbkCgH8sflJXZIhbN6H4Ot4sjdvWwz+nqR+6xN9A+uANt+RdLjooShzhXGN+LWVcPm/rj27ZhC75yvuwvFCSuTDyX3qhJfHPG23NmpWe4DFYe+UN2j8nVMcy/5F2pTr5mL1OOYayyaDJW0DL8NWFEpK7RWKyB4tG9KB44gNzgAbTnbec599gByJbVxbedNtXRm9MOloYrdC83+4Dxw5g/86KnxylI31ZSGtpamNF4DqrpQwxV62PJGOZf9vaCSW+cfHDJbT2EXMGra0lO9zmtlrWp6yb0KWVNXaN8j5be5ZYWNLRuhYv1bDfme9SERuti5E69bvVCWT1VHcCVC/vLC3hIb4P0mvl7n9AH2/Dchs29dnz7XXA3MH0MRy68bvdC2BdLDt3owEN41+nhumTlKwt4DFsLeHx0wdtz5kRN/NPdI0a3r9dMUpNVI7Xr1IeHB2xHrBkXGElq6IZBr4tGwwrku2e1+/RBHCz1WqpFYoYx2g/MSI/p+EUn1kPY+aj0kj2A+ztfxyX1EaB3n9NbfBZHTjk9ak4M2f5BnPP8un0YmrJ7jq1bvfscR6zco2xdl564jXuQd+J7fmJp0RNzSZzUos+6zBlL34DQb8fcBrsHoPi+v/drAsUzh61erNzaLZUJihHrcsQkwELhjNP71hdrr6QsypBbK44pUHy/0mAVh1EN80pclkpCdbtiwogwodH4rI9j/u0xi2vuweeQU4ahDE90DXfVBy+OuV/3stzYbnx5tKwJlV5J3+qC86urLV807dNS+uJw+oYjLhR2Y35ckhpBLuivQYrPqXaBIwKa0KdkaUKjEVUp3Y6vZSdqiu2TRRlKWlzi71ETGm1EI3dowO7lKlzwD+O6iPMXjkFeN/ke155HU/vxi3NeR0yUfGnqD1bY0gORycFZa1iifxhl7DplUtb0M6nF0K1WmkbUaEVZxQEvOWJy9yI+nHbGCU4fdDlicu80TkzIvV6sdG3jMCSOvLWyqNcRk2uXpvbjyLQcDeP+8uheqDgzE0dKQ2GtRGZP47VT9rNinbv+d7No0VXl0mGt+sy8Z8ycATGBr94fQ9tWe+jgrTJP7MxxLHiMuX60OnOnWtYeQvvaEkfnwJkv02U7V+45Zrh6sXLo4sxFyxlTc2z8qQWfZ1EGlcckrqsesMDCqHCAHg8dxoEZGbtowogwo9G4rB1k4nyslXmIO9C+Va6NYT5gfpUW4PFT4Xt5ybyxFZuQW6uG9Zbnj5XTV/WI0lY5Rryj6PSvfz4JYA1auvuBwoQ3+dSeU2+ySc9M6FPKYkajkrLOM67aSPe94aKXWvtkUQaVR5TWVThdHjqMXcwMH5rQaGMauX0lA3VFzz7sLM3vUoBX2/NiOu+2NrL1OD0yb6zze7i/Rw3lc8KqqFn8Tv/eaxRbecat00W8e+EsRtfZwyzvk3liF06Xe1CyqEeCPGo1dIOybEyNBpR09tPy/EHn9qXZzyyHa2bujwER7EsrOuXvuPSYKY1M4bLqKfPFujxnO3BBcT6aUr1uvkgVpyofGfYb8/mqSKu5LqShz0ydMXMGhNNwhd2YhbOAx+ABdA4eAGSYXsCEfzWnq55Nbq4M92KZ5XRO+pzR6rXVLksMxtVzS+eOCSPCuEadoXRxHPjix2NYdOYgIsqhSoS2H8sfe6G8ME1oGvG1FZpcxU399FvuutdyHiqSaJALJvQpVTOu0RjPuPZ7w2CbmCuDvhZV9bTLEoOxStvErwmNNoORK0O/7AUJoqj24eH1Py8vnBAVvI73tes0tR8H4Sxg0rMHe3r2AO4FIepYh6Cs0zB0/ek2g0b9ZU5+fg9WWgvVfFbVGVNpd3fc4zhw6kqyX20tJku+oWKlpc/MnDHjBoTTPPacrRcBZ3U4awGEXe/4Nl+OmFeWSVObLMMnuO4swtDajYqhXpXVi1cWPcaVuaR5xYQRkY1G47GGM4en5Ly55o+lxVPmSrbJCqCyuuJbruGKarVDT0ZxteWJrHGin/7i559opFefICb0KTXJRqMyBFvm/PE9upTfoyY02hxGrv6GzDKPbFR60GTlQvdwRbXyYX1eLwG56tdJItvz214HnJUit/cMY/vGV7DStSBJQCaZX0rL0HUXvDk06i5xrcd/xOU5IN+x2u4ZrtI7JrmE9bTplyKeFvXTbbyQaeozkzljWRkQnqaamUDx6COYHbOHNC1bIXcnsCBOCtbAPvfEyOgkizLo5qEbrgqaQMZVwqZ42YQRYV6jyVi3bnwBbV3A4tjj+MI1fyy9ryhqiNUkrrkdsartlaweVZOruBGVfj9yA/ZS94szviGKFWnV54IJfUpNzGs0gFfgMx7VRgHppH4pizLo5qEbrgqEQMZVwqZ02YRGG9/Ivej0DHjn01RHqoZdTeGk2xGrHiH6zuyn9lwzZyhkdISoEHHr5Etv9iLOn3sKBwPmGflCZn6apqGrCt/4GlUlTfM3SiN9uN9ZMv/KrBqSGBUnqHxJ4gSl0xzX0tancWcsOwNiC9qfPYScb+zBsrvKexRJE8uQL/knCyIEGbSy0qA/jfjSCP/jnEUZ7Hk1wfVszW8p1TFeWfQYx+elH8OEEZGVRuOxBmSPO2vlT4zh61MT1kIb1uIVXTtw+0b32rLhetOn6w4p+47Zi924r8qxrraSfvwocZIVE33Pc2v+acs5lV68a4kWMfHXJt1zE/qUEmalUUDvGS+1Ed+jloDi8dBjnK4yy6mZ0GizGLnnZWlwWaRj4AlrXliZin0k+yMNuRY+8N+3z2XfMXshkMr7EQbp7Kf2cvfWaneu2NYKddXSdIULOIxXp4ewc3RfRR1XuvadCsgi80tpG7pSgWbRqAnYJY3Iiok+fa/q3Y5RGcY4dwwnXPuHleL4n5WQXuGqcZxK6T1fJgikm6YJfQb5I6mVOjsDwimysweRbAwr+yjB2pfIHn5VMtxcCyJ0HthhbSJrhcUa5JzNnItvu4ZqJaShFhnIbX0H7WsnrX3J8P4j9ip4GZRh4dTf4trAG2jr2oHOAxtK+66pOQ3Ft4/bwxfjlkWHcUJmUdFMGBGZajQW634s/4Gz8qdaxl4+Jqjl7kdewPLCI6UNx0P1Fgp2AsULk2jrkg3K38Gt1v58a9Di2vzZH11bWyXHbQ0CnwN/wuq8xMneU6y0V596nmX7ircCVoVU8ev0a0KfUpVMNSoZ6jzjpTaS9wvfo7IiqVpoR4uHDmMDOjah0aYycmXluB7ZnHkb9jy6zdq82d6DbDXyTu9A4QO1eqK9at1ov2zg/Arum/4MV7AaK1ybPwc1kVoMIb/uFezs+czawwsXnnKW1z+ND6dlPzNvmlbec1OY6ShvLB2UduC1WHUC0CFDEk9g09xZWHW39pqqNMYD88rgoglDt6k0aoJxSSNO26s98FTbw+799SxaM3UEJwdkmwZ5Vh6w9jGz9hkTx1323MNw5fL2pXx0ni8TFTWfpgl9SqmNOWOZGxA4jvmXgeUbnkSbLHbgLGCxKKsq+pakLx4dwmz+EG5/UMK5wl4dw9dv/VpjjlV0gy+cegTzd72D9kHl5I3hmmtlQ/NlmMBXLz2OhY1P47aRkbJxfXUSxQuvenoV9MuizziaULwQJoyI7DUqzpSe9ko9QBXL2B/HtbEnkRtZA9nfruhoO0pvYbQl7iwO4XaXTuSDxvxbp5DbZe9r5o2vr62k5fJwUouXWJu0n8HXvv3QvGWrz5kJfUpNsteo/jPuaSO+R7WfbcT4W5Wmmk1otBmN3PPnNuNy7z78eEA2hbY3hrY2QJ47i/fOHfHsJ3Zp/CkcxD78uH8Y3Y4TJps/Hzn3e9xfZa8liXOk4xVs7+l1HLyzOOmap3P+3DPA4HZsKqU5hcLEQZwYBzY/ukdzYRGvMvTrJMuSAw8P/BCjsoiJtbCDbH79Jn7jWT7dm35WZyYM3WbUqAneHo2UFrCRtv8D3vPto2fnfxHvnnwGl9f/3KVl0eozeG0c1n56QbvLePKJeL5M1NNkmib0qcp7y40bN26ok7R+szcg0io502lEAiaMCGq0EVu6OctkQp9CghptTj00YqlNaJRGbiO2dPOWyYShS402rx4areQm9OmuY+pzxmhAuPHyuFYCJowIarTWVmF8RcCEPiVtalQR5m+tBExolEZura3C+G4CJgxdatRNmMe1EDChT395UnXGaED48fK8FgImjAhqtJYWYVw3ARP6lPSpUTdlHtdCwIRGaeTW0iKM6ydgwtClRv2UeZ6UgAl9BpUlNWeMBkQQXl5LSsCEEUGNJm0NxvMTMKFPyYMa9ZPmeVICJjRKIzdpazBeEAEThi41GkSa15IQMKHPauVIxRmjAVENL68nIWDCiKBGk7QE4wQRMKFPyYcaDaLNa0kImNAojdwkLcE41QiYMHSp0Wq0eT0uARP6DCtDzc4YDYgwvLwXl4AJI4IajdsKDF+NgAl9Sl7UaDXivB6XgAmN0siN2woMH0bAhKFLjYYR5704BEzoMyr/mpwxGhBReHk/DgETRgQ1GqcFGDaMgAl9Sn7UaBh13otDwIRGaeTGaQGGjSJgwtClRqOo874uARP61Mk7sTNGA0IHL8PoEjBhRFCjuvQZLoqACX1KntRoFHne1yVgQqM0cnXpM5wOAROGLjWqQ55hdAiY0KdOvhImkTNGA0IXL8PpEDBhRFCjOuQZRoeACX1KvtSoDn2G0SFgQqM0cnXIM4wuAROGLjWqS5/hogiY0GdUnu77sZ0xGhBufDyulYAJI4IarbVVGF8RMKFPSZsaVYT5WysBExqlkVtrqzC+m4AJQ5cadRPmcS0ETOgzbnliOWM0IOLiZfgwAiaMCGo0jDjvxSFgQp+SPzUapxUYNoyACY3SyA0jzntxCZgwdKnRuK3A8NUImNBntbzCrms7YzQgwjDyXlwCJowIajRuKzB8NQIm9Cl5UaPViPN6XAImNEojN24rMHwYAROGLjUaRpz34hAwoc84+bvDajljNCDcyHhcKwETRgQ1WmurML4iYEKfkjY1qgjzt1YCJjRKI7fWVmF8NwEThi416ibM41oImNBnLeWJdMZoQNSCl3H9BEwYEdSonzLPkxIwoU8pCzWatEUYz0/AhEZp5Pop87wWAiYMXWq0lhZhXDcBE/p0p5/kONQZowGRBCnjVCNgwoigRqvR5vW4BEzoU8pAjcZtCYavRsCERmnkVqPN60kImDB0qdEkLcE4QQRM6DMon7jXqjpjNCDiomT4MAImjAhqNIw478UhYEKfkj81GqcVGDaMgAmN0sgNI857cQmYMHSp0bitwPDVCJjQZ7W84l4PdMZoQMTFyPBhBEwYEdRoGHHei0PAhD4lf2o0TiswbBgBExqlkRtGnPfiEjBh6FKjcVuB4asRMKHPankluX7LjRs3biSJyDgkQAIkQAIkQAIkQAIkQAIkQALJCQT2jCVPjjFJgARIgARIgARIgARIgARIgAR0CNAZ06HEMCRAAiRAAiRAAiRAAiRAAiSQMgE6YykDZXIkQAIkQAIkQAIkQAIkQAIkoEOAzpgOJYYhARIgARIgARIgARIgARIggZQJ0BlLGSiTIwESIAESIAESIAESIAESIAEdAnTGdCgxDAmQAAmQAAmQAAmQAAmQAAmkTIDOWMpAmRwJkAAJkAAJkAAJkAAJkAAJ6BCgM6ZDiWFIgARIgARIgARIgARIgARIIGUCdMZSBsrkSIAESIAESIAESIAESIAESECHAJ0xHUoMQwIkQAIkQAIkQAIkQAIkQAIpE6AzljJQJkcCJEACJEACJEACJEACJEACOgTojOlQYhgSIAESIAESIAESIAESIAESSJkAnbGUgTI5EiABEiABEiABEiABEiABEtAhQGdMhxLDkAAJkAAJkAAJkAAJkAAJkEDKBOiMpQyUyZEACZAACZAACZAACZAACZCADgE6YzqUGIYESIAESIAESIAESIAESIAEUiZAZyxloEyOBEiABEiABEiABEiABEiABHQI0BnTocQwJEACJEACJEACJEACJEACJJAyATpjKQNlciRAAiRAAiRAAiRAAiRAAiSgQ4DOmA4lhiEBEiABEiABEiABEiABEiCBlAnQGUsZKJMjARIgARIgARIgARIgARIgAR0CdMZ0KDEMCZAACZAACZAACZAACZAACaRMgM5YykCZHAmQAAmQAAmQAAmQAAmQAAnoEKAzpkOJYUiABEiABEiABEiABEiABEggZQJ0xlIGyuRIgARIgARIgARIgARIgARIQIcAnTEdSgxDAiRAAiRAAiRAAiRAAiRAAikToDOWMlAmRwIkQAIkQAIkQAIkQAIkQAI6BOiM6VBiGBIgARIgARIgARIgARIgARJImQCdsZSBMjkSIAESIAESIAESIAESIAES0CHw/wGvDI4uYfIB8QAAAABJRU5ErkJggg=="
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling<a class=\"anchor\" id=\"H8\"></a>\n",
    "A machine learning pipeline usually consists of one or more transformers and an estimator. Transformers relay the data to the receptors of the estimator and the estimator does the learning and decision making. In our context, we have two transformers: the first one turns the series of words into features of words and the other transforms these set of features into numerical vectors that can be read by the estimator.\n",
    "\n",
    "For our transformer, we could make some transformation functions and apply them before we run the model. However, this approach is not very portable or flexible. The other solution is to make a transformation class which can be piped with the estimator providing extensive portability and support for automated hyper parameter tuning.\n",
    "\n",
    "Our model's pipeline will consist of the following steps:\n",
    "![image.png](attachment:image.png)\n",
    "We must create our own transformer for the orange sections and we will use Scikit Learn's vectorizer and estimator for the green steps. Our output from applying extraction will not be numerical so we need a vectorizer turn this numerical.\n",
    "\n",
    "But before going any step further, it is time to split the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the data<a class=\"anchor\" id=\"H9\"></a>\n",
    "We split the data 60%, 20% and 20% to training set, validation set and testing set. Because Sklearn's train_test_split function can split only one data set at a time, we need calculate the second split. The first split is 80:20 as we want 20% left out for testing set and after that we want a ratio that splits the remaining 80% to validation set of 20% and training set of 60%: \n",
    "<br>$split_2*0.80 = 0.20 $ \n",
    "<br>$split_2 = 0.20 / 0.80$ \n",
    "<br>$= 0.25 $\n",
    "\n",
    "There is still one problem. We cannot split the words randomly because the orders of words in a sentence are important for our transformer. We can either first structure the data to sentences and get slightly incorrect split ratios or first transform the data to features and then split by words. However, the latter prevents us from piping the transformer conveniently with the classifier thus we accept the slight inaccuracy of split ratios. This also marginally reduce the randomness in our splits as the words in sentences are not random.\n",
    "\n",
    "We also want to get rid of the index \"_#_\" as the order of words in a sentence is obvious and maintained. In addition, we reduce the data to 2 000 sentences because my laptop is not very resourceful. We do the reduction with random sampling as we cannot be sure that the order of sentences in the file is random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Size    Ratio\n",
      "Size of test         5080   18.6 %\n",
      "Size of validation   5616   20.5 %\n",
      "Size of train       16669   60.9 %\n",
      "Total               27365  100.0 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Setting random states for\n",
    "# reproductability:\n",
    "random_state = 44 \n",
    "np.random.seed(random_state)\n",
    "\n",
    "# Removing the word position index\n",
    "df.index = df.index.droplevel('#')\n",
    "\n",
    "# and reducing the sample size with random sampling\n",
    "random_sample = np.random.choice(df.index.unique(), \n",
    "                                 2000,replace=False)\n",
    "df = df.loc[random_sample]\n",
    "\n",
    "# Now to the actual splitting\n",
    "X, y = df['Word'], df['Part of Speech']\n",
    "\n",
    "train_valid_index, test_index = train_test_split(df.index.unique(), test_size=0.2, random_state=random_state)\n",
    "train_index, valid_index = train_test_split(train_valid_index, test_size=0.25, random_state=random_state)\n",
    "\n",
    "X_test, y_test   = X.loc[test_index],  y.loc[test_index]\n",
    "X_valid, y_valid = X.loc[valid_index], y.loc[valid_index]\n",
    "X_train, y_train = X.loc[train_index], y.loc[train_index]\n",
    "\n",
    "\n",
    "print(\n",
    "    pd.DataFrame([\n",
    "    [y_test.shape[0],  '{:.1f} %'.format(round(y_test.shape[0]/df.shape[0], 3)*100)],\n",
    "    [y_valid.shape[0], '{:.1f} %'.format(round(y_valid.shape[0]/df.shape[0], 3)*100)],\n",
    "    [y_train.shape[0], '{:.1f} %'.format(round(y_train.shape[0]/df.shape[0], 3)*100)],\n",
    "    [df.shape[0], '{:.1f} %'.format(round((y_train.shape[0]+y_valid.shape[0]+y_test.shape[0])/df.shape[0], 3)*100)]\n",
    "    ], \n",
    "    index = ['Size of test','Size of validation','Size of train', 'Total'],\n",
    "    columns = ['Size','Ratio'])\n",
    "     )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split ratios seem to be adequate and we move on to make the transformer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformation and Feature Engineering<a class=\"anchor\" id=\"H10\"></a>\n",
    "We pick some features from the actual word and some features related to the position of the word in the sentence. We will start with checking if the word is in upper or lower case, is capitalized, has hypend or is number. We also take the last 1, 2 and 3 letters of a word, word's length and the word itself. Finnish words have hypends if they are combination words with same vowels in the intersection (ie. _virka-asia_). Generally prefixes hold little importance in Finnish. From the sentence, we use the information of what was the previous word and what is the next word, and if the word is first or last in the sentence.\n",
    "\n",
    "The transformer is the largest block of code we need to write. We build it as a Python class and inherit BaseEstimator and TransformerMixin from Scikit Learn to make it work as a component of Scikit Learn's pipeline. The most confusing part of the transformer could be that we pass the extraction method's name as an argument and then convert the name to the extraction function itself with built-in function _getattr_. We do so to make the extraction method as a replaceable component but more of this later. This trick keeps the script DRY (Don't repeat yourself)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "\n",
    "\n",
    "class WordFeatureExtractor(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    \n",
    "    def __init__(self, extraction_function='extraction_simple'):\n",
    "        'Transforms pandas series to list of word features'\n",
    "        \n",
    "        # We pass \"extraction_function\" as an argument\n",
    "        # so we can later add new extraction methods\n",
    "        # with means of inheritage\n",
    "        \n",
    "        self.extraction_function = extraction_function\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        \n",
    "        # There is nothing to fit on here but\n",
    "        # Sklearn pipeline requires a fit method\n",
    "        \n",
    "        return self\n",
    "\n",
    "    \n",
    "    def transform(self, X):\n",
    "        'Transform a pandas series of words to list of dictionaries'\n",
    "        \n",
    "        # Next we turn the series to list of words that are in list of sentences\n",
    "        # We use groupby to group the series by sentence, then we turn each sentence\n",
    "        # to list with lambdas (sent.values.tolist()) and finally we turn the whole \n",
    "        # series to list.\n",
    "        X_sents = X.groupby(X.index.names, sort=False).apply(lambda sent: sent.values.tolist()).tolist()\n",
    "        return self._transform_sentences(X_sents)\n",
    "\n",
    "    \n",
    "    def _transform_sentences(self, X):\n",
    "        'Transforms list of sentences to list of dictionaries'\n",
    "        \n",
    "        # The method's name starts with underscore\n",
    "        # to indicate a private method.\n",
    "        # This method relies on the attribute:\n",
    "        # \"extraction_function\"\n",
    "        \n",
    "        X_transformed = []\n",
    "        for sentence in X:\n",
    "            for word_index in range(len(sentence)):\n",
    "                # index is a position of a word\n",
    "                # in a sentence\n",
    "                extractor = getattr(self, self.extraction_function)\n",
    "                x_dict = extractor(sentence, word_index)\n",
    "                # or directly change to \"x_dict = self.extraction_simple(sentence, word_index)\"\n",
    "                \n",
    "                X_transformed.append(x_dict)\n",
    "        return X_transformed\n",
    "\n",
    "\n",
    "    def extraction_simple(self, sentence, index):\n",
    "        return {\n",
    "                'word': sentence[index],\n",
    "                'length': len(sentence[index]),\n",
    "                'has_hyphen': '-' in sentence[index],\n",
    "                'is_first': index == 0,\n",
    "                'is_last': index == len(sentence) - 1,\n",
    "                'is_capitalized': sentence[index].capitalize() == sentence[index],\n",
    "                'is_upper': sentence[index].isupper(),\n",
    "                'is_lower': sentence[index].islower(),\n",
    "                'is_digit': sentence[index].isdigit(),\n",
    "                'suffix_1': sentence[index][-1:],\n",
    "                'suffix_2': sentence[index][-2:],\n",
    "                'suffix_3': sentence[index][-3:],\n",
    "                'prev_word': sentence[index - 1] if index > 0 else '',\n",
    "                'next_word': sentence[index + 1] if index < len(sentence) - 1 else '',\n",
    "                }\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we test the output of our transformer. We take the the first sentence in training set check how the second word looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'has_hyphen': False,\n",
       " 'is_capitalized': True,\n",
       " 'is_digit': False,\n",
       " 'is_first': False,\n",
       " 'is_last': False,\n",
       " 'is_lower': False,\n",
       " 'is_upper': False,\n",
       " 'length': 16,\n",
       " 'next_word': 'tarkoitetaan',\n",
       " 'prev_word': '1.1.2.2',\n",
       " 'suffix_1': 'a',\n",
       " 'suffix_2': 'la',\n",
       " 'suffix_3': 'lla',\n",
       " 'word': 'Ohjausvaihteella'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extr = WordFeatureExtractor()\n",
    "extr.transform(X_train.loc[X_train.index[0]])[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The transformer seems to be working correctly. Next we can set up our pipeline.\n",
    "As our transformer produces list of dictionaries, we need to convert these to numerical matrixes. Fortunately Sklearn has DictVectorizer which handles all of the transformation for us: dict to matrix and strings to dummies. It also remembers the feature names from the fit method in case we want to inspect them later.\n",
    "\n",
    "We are going to use Decision Tree classifier. It is a good choice for the task as it is fast. It is also prone to overfit but it should not be a big deal here: Finnish language is known for lack of exceptions.\n",
    "\n",
    "Lets get to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "\n",
    "pos_tagger = Pipeline([\n",
    "    ('extractor',WordFeatureExtractor()),\n",
    "    ('vectorizer', DictVectorizer(sparse=False)),\n",
    "    ('classifier', DecisionTreeClassifier(criterion='gini'))\n",
    "    ])\n",
    "\n",
    "pos_tagger.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model is now trained and ready to put on test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          A       0.76      0.53      0.63       412\n",
      "       Abbr       0.88      0.88      0.88         8\n",
      "        Adp       0.94      0.92      0.93       126\n",
      "        Adv       0.88      0.90      0.89       164\n",
      "      AgPcp       0.67      0.29      0.40        21\n",
      "         CC       1.00      0.99      0.99       282\n",
      "         CS       1.00      1.00      1.00        94\n",
      "          N       0.88      0.95      0.91      2438\n",
      "   NON-TWOL       0.84      0.50      0.63       101\n",
      "        Num       0.99      0.97      0.98       559\n",
      "     PrfPrc       0.90      0.85      0.87       214\n",
      "       Pron       0.94      0.96      0.95       355\n",
      "     PrsPrc       0.87      0.81      0.84       166\n",
      "          V       0.91      0.92      0.91       676\n",
      "\n",
      "avg / total       0.90      0.90      0.89      5616\n",
      "\n",
      "Accuracy: 90.0%\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "y_pred = pos_tagger.predict(X_valid)\n",
    "print(metrics.classification_report(y_valid, y_pred))\n",
    "print('Accuracy: {:.1f}%'.format(round(metrics.accuracy_score(y_valid, y_pred), 3)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "90% accuracy is not bad at all and percision and recall seem to be somewhat balanced. We care evenly correct classifications, whether it is negative or positive for a class, so there should be little reason to weight recall or percision of a class over the other. Our model does not perform well on agent particles or NON-TWOL most likely because they are somewhat rare but on the other hand coordinating conjunction (CS) it did classify completely correctly even though the class size is small.\n",
    "\n",
    "Next we will go a bit deeper on what the model confuses and gets wrong. We will use confusion matrix for the job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_confusion(y_true, y_pred):\n",
    "    conf = metrics.confusion_matrix(y_true, y_pred)\n",
    "    conf_norm = conf / conf.sum(axis=1, keepdims=True)\n",
    "    labels = np.unique(np.concatenate((y_true, y_pred), axis=0))\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(conf_norm, cmap='RdYlGn_r', interpolation='nearest')\n",
    "    fig.colorbar(cax)\n",
    "\n",
    "    ax.set_xticks(np.arange(len(labels)))\n",
    "    ax.set_yticks(np.arange(len(labels)))\n",
    "\n",
    "    ax.set_xticklabels(list(labels), rotation='vertical')\n",
    "    ax.set_yticklabels(list(labels))\n",
    "    ax.set_xlabel('Predicted')\n",
    "    ax.set_ylabel('Actual')\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x29a52d3cb70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "# %matplotlib inline is a method of\n",
    "# Jupyter Notebook to embed plots.\n",
    "# Don't copy it to your script.\n",
    "\n",
    "plot_confusion(y_pred, y_valid)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confusion matrix plot above is normalized with the actual value (horizontally). For example, agent particles (AgPcp) are clearly confused to nouns (N) and adjectives (A) but about 50% of them are classified right.\n",
    "\n",
    "The imbalance of tags is visible in this plot: The model tags other classes as nouns, which is the largest class, but does not confuse nouns to other classes as easily (the vertical line of N is more colourful than the horizontal line of N). \n",
    "However, the most important observation here is that adjectives, which is fourth larges group and has third worst score, are often confused with nouns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_example_dict(x, y_pred, y_true):\n",
    "    '''Returns a dictionary with examples\n",
    "    Structure : {True values: {Predicted values: [List of examples]}}'''\n",
    "    \n",
    "    x = np.array(x)\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    labels = np.unique(np.concatenate((y_true, y_pred), axis=0))\n",
    "    examples = {true_label:{pred_label:[] for pred_label in labels} for true_label in labels}\n",
    "    for index in range(len(y_true)):\n",
    "        examples[y_true[index]][y_pred[index]].append(x[index])\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mukainen',\n",
       " 'myönnettävistä',\n",
       " 'tavanomaisen',\n",
       " 'mittanormaalia',\n",
       " 'ETY-mittanormaalia']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_example_dict(X_valid, y_pred, y_valid)['A']['N'][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above five words are examples of words that were mistaken as nouns even though they are adjectives. I won't go details what these words mean but in Finnish the lengths of the words above resemble typical noun and the last three letters could easily exist in a noun. My hypothesis is that those words are incorrectly classified due to that the last three letters at the end are not enough to distinguish the difference.\n",
    "\n",
    "An easy solution would be to add just more letters to the suffix features. However, as I was digging deeper to the problem I got a better idea: in Finnish, syllables play significant role. Syllables are usually about three letter strings that make up the words. I don't know how it works in English but in Finnish you could divide word such as \"myönnettävistä\" to the following syllables \"myön-net-tä-vis-tä\". Together those last two syllables are very hard to confuse with nouns or any other PoS tags. Coming up with a proper syllable splitter involved getting my hands on The Dictionary of Modern Finnish and playing awhile with regular expressions.\n",
    "\n",
    "I found out that a syllable ends to:\n",
    "<br> A) consonant, that is not the last letter in a way that next syllable starts one and only one consonant,\n",
    "<br> B) third vowel if there are more than two sequential vowels or\n",
    "<br> C) second vowel in a sequence of two vowels in some rarer cases for an unknown reason  \n",
    "\n",
    "After experimenting with regular expressions, I came up with the following string:\n",
    "[bcdfghjklmnpqrstvxzw]?[aeiouyäö]{1,2}(?:(?=[aeiouyäö])|[bcdfghjklmnpqrstvxzw]{0,2}$|[bcdfghjklmnpqrstvxzw]{0,3}(?=[-bcdfghjklmnpqrstvxzw]))\n",
    "\n",
    "<br> To break this down:\n",
    "1. [bcdfghjklmnpqrstvxzw]? means that the syllable can start with a consonant or without (qualifier \"_?_\")\n",
    "2. Then the syllable can have one or two vowels: [aeiouyäö]{1,2}\n",
    "2. And then the syllable either end\n",
    "<br> to third vowel without capturing it: (?=[aeiouyäö]), or \n",
    "<br> to consontants that are at the end of the word: [bcdfghjklmnpqrstvxzw]{0,2}$, or\n",
    "<br> to the second last consonant in sequential consonants: [bcdfghjklmnpqrstvxzw]{0,3}(?=[-bcdfghjklmnpqrstvxzw]\n",
    "\n",
    "Next we try this out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['myön', 'net', 'tä', 'vis', 'tä']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "re.findall(('[bcdfghjklmnpqrstvxzw]?[aeiouyäö]{1,2}(?:(?='\n",
    "            '[aeiouyäö])'\n",
    "            '|[bcdfghjklmnpqrstvxzw]{0,2}$'\n",
    "            '|[bcdfghjklmnpqrstvxzw]{0,3}(?=[-bcdfghjklmnpqrstvxzw]))'),\n",
    "           'myönnettävistä')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It works as we expected. Now we just need to apply this to our extractor. Because copy-pasting code is ugly, we just make an advanced feature transformer that inherits all the other methods of the original transformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordFeatureExtractorExtended(WordFeatureExtractor):\n",
    "    \n",
    "    # We set the regular expression by putting the vowels and\n",
    "    # consonants with .format method. This way it is slightly\n",
    "    # more readable but note the double curly brackets in the \n",
    "    # numerical qualifiers. The doubles do get removed by itself.\n",
    "    \n",
    "    syllable_expr = r'[{con}]?[{vow}]{{1,2}}(?:(?=[{vow}])|[{con}]{{0,2}}$|[{con}]{{0,3}}(?=[-{con}]))'.format(\n",
    "        con='bcdfghjklmnpqrstvxzw', vow='aeiouyäö')\n",
    "        \n",
    "    \n",
    "    def extraction_complex(self, sentence, index):\n",
    "        'Extract word features with syllables'\n",
    "        \n",
    "        # We normalize the word (turn lower case) \n",
    "        # as I don't think capitalization \n",
    "        # plays a role here.\n",
    "        word_normalized = sentence[index].lower()\n",
    "        \n",
    "        # Split the word according to the syllables\n",
    "        splitted = re.findall(\n",
    "            self.syllable_expr, word_normalized)\n",
    "        \n",
    "        # We also take the last syllable in the previous \n",
    "        # and in next word\n",
    "        splitted_prev = '' if index == 0 else re.findall(\n",
    "            self.syllable_expr, sentence[index-1])\n",
    "\n",
    "        splitted_next = '' if index == len(sentence) - 1 else re.findall(\n",
    "            self.syllable_expr, sentence[index+1])\n",
    "        \n",
    "        return {\n",
    "                'word': sentence[index],\n",
    "                'length': len(sentence[index]),\n",
    "                'is_first': index == 0,\n",
    "                'is_last': index == len(sentence) - 1,\n",
    "                'is_upper': sentence[index].isupper(),\n",
    "                'is_lower': sentence[index].islower(),\n",
    "                'is_digit': sentence[index].isdigit(),\n",
    "                'is_capitalized': sentence[index].capitalize() == sentence[index],\n",
    "                'suffix_1': splitted[-1] if len(splitted) > 1 else '',\n",
    "                'suffix_2': splitted[-2] if len(splitted) > 2 else '',\n",
    "                'suffix_3': splitted[-3] if len(splitted) > 3 else '',\n",
    "                'prev_word_suffix': splitted_prev[-1] if len(splitted_prev) > 0 else '',\n",
    "                'next_word_suffix': splitted_next[-1] if len(splitted_next) > 0 else '',\n",
    "                'has_hyphen': '-' in sentence[index]\n",
    "                }\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some might argue that we made the code unnecessarily complicated with the _getattr_ trick. In fact, we could have avoided using the function by overriding the original extractor. This is simply done by naming the new method in the new class with the same name as it is in the parent class (in this case WordFeatureExtractor). However, doing so prevents testing multiple extraction methods with grid search or with other automatic hyper parameter tuning tools as they allow changing only the arguments in the initiation (considered as hyper parameters in this context). On the other hand, you probably should just use one class containing all of your extraction methods instead of using inheritage as we did here. The only reason we used inheritage was to keep this guide clean and easier to follow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But now to test the updated model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'has_hyphen': False,\n",
       " 'is_capitalized': True,\n",
       " 'is_digit': False,\n",
       " 'is_first': False,\n",
       " 'is_last': False,\n",
       " 'is_lower': False,\n",
       " 'is_upper': False,\n",
       " 'length': 16,\n",
       " 'next_word_suffix': 'taan',\n",
       " 'prev_word_suffix': '',\n",
       " 'suffix_1': 'la',\n",
       " 'suffix_2': 'teel',\n",
       " 'suffix_3': 'vaih',\n",
       " 'word': 'Ohjausvaihteella'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extr = WordFeatureExtractorExtended(extraction_function='extraction_complex')\n",
    "extr.transform(X_train.loc[X_train.index[0]])[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Works great. Now just update the pipeline, fit it and predict the validation set just as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tagger_adv = Pipeline([\n",
    "    ('extractor',WordFeatureExtractorExtended(extraction_function='extraction_complex')),\n",
    "    ('vectorizer', DictVectorizer(sparse=False)),\n",
    "    ('classifier', DecisionTreeClassifier(criterion='gini'))\n",
    "    ])\n",
    "\n",
    "pos_tagger_adv.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          A       0.87      0.74      0.80       412\n",
      "       Abbr       0.55      0.75      0.63         8\n",
      "        Adp       0.94      0.94      0.94       126\n",
      "        Adv       0.85      0.90      0.88       164\n",
      "      AgPcp       0.35      0.33      0.34        21\n",
      "         CC       1.00      0.99      1.00       282\n",
      "         CS       0.99      1.00      0.99        94\n",
      "          N       0.90      0.95      0.93      2438\n",
      "   NON-TWOL       0.78      0.38      0.51       101\n",
      "        Num       0.97      0.98      0.98       559\n",
      "     PrfPrc       0.87      0.90      0.88       214\n",
      "       Pron       0.94      0.95      0.94       355\n",
      "     PrsPrc       0.91      0.83      0.87       166\n",
      "          V       0.93      0.90      0.92       676\n",
      "\n",
      "avg / total       0.91      0.91      0.91      5616\n",
      "\n",
      "Accuracy: 91.5%\n"
     ]
    }
   ],
   "source": [
    "y_pred = pos_tagger_adv.predict(X_valid)\n",
    "print(metrics.classification_report(y_valid, y_pred))\n",
    "print('Accuracy: {:.1f}%'.format(round(metrics.accuracy_score(y_valid, y_pred), 3)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the difference? We increased precision of adjectives about 0.11 and recall about 0.21. This means that the model is now more eager to classify words to adjectives (recall) and at the same time classifies fewer non adjectives as adjectves (precision). Also, accuracy rose 1.5% which is something."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Evaluation and Conclusion<a class=\"anchor\" id=\"H11\"></a>\n",
    "We could increase the accuracy with similar tricks we did endlessly but the model is already adequate. You could, for example, make the model recursive meaning that you fit the model also using the tags from previous words and predict the first words per sentence, then add the predictions to the next words' features and predict the tag of that word and so on. You could also try different algorithms or remove or add new features. However, small increases of accuracy many times require expontentially complex and resource intensive models. \n",
    "\n",
    "Next we just get the final accuracy scores from the test set. We did not take many steps in our validation phase but we had too much data not to spend on untouched test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Score\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          A       0.87      0.73      0.79       345\n",
      "       Abbr       0.72      0.81      0.76        16\n",
      "        Adp       0.95      0.91      0.93       109\n",
      "        Adv       0.89      0.84      0.86       158\n",
      "      AgPcp       0.44      0.29      0.35        14\n",
      "         CC       1.00      1.00      1.00       265\n",
      "         CS       1.00      0.97      0.99       115\n",
      "          N       0.89      0.95      0.92      2132\n",
      "   NON-TWOL       0.43      0.16      0.24        61\n",
      "        Num       0.98      0.98      0.98       523\n",
      "     PrfPrc       0.84      0.84      0.84       186\n",
      "       Pron       0.92      0.93      0.93       334\n",
      "     PrsPrc       0.96      0.84      0.89       160\n",
      "          V       0.91      0.89      0.90       662\n",
      "\n",
      "avg / total       0.91      0.91      0.91      5080\n",
      "\n",
      "Accuracy: 91.0%\n"
     ]
    }
   ],
   "source": [
    "y_pred = pos_tagger_adv.predict(X_test)\n",
    "print('Final Score')\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "print('Accuracy: {:.1f}%'.format(round(metrics.accuracy_score(y_test, y_pred), 3)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy score is fine and the model is ready for production. You can save the model on your disk with pickle or joblib to use it later or in another script. Also, depending on the structure of your to-be-tagged data, you may want to bypass the series to list section in the transform method. This can be done with simple checking of the data type (ie. \"_if isinstance(X, pd.Series):_\") or using a setter and an _if_ statement. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory of the first model:  1312174 bytes.\n",
      "Memory of the second model: 845743 bytes.\n",
      "Memory consumption change:  -36.0%\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import sys\n",
    "mdl_1 = pickle.dumps(pos_tagger)\n",
    "mdl_2 = pickle.dumps(pos_tagger_adv)\n",
    "\n",
    "mdl_1_memory = sys.getsizeof(mdl_1)\n",
    "mdl_2_memory = sys.getsizeof(mdl_2)\n",
    "print('Memory of the first model:  {} bytes.'.format(mdl_1_memory))\n",
    "print('Memory of the second model: {} bytes.'.format(mdl_2_memory))\n",
    "print('Memory consumption change:  {:.1f}%'.format(round((mdl_2_memory-mdl_1_memory)/mdl_1_memory*100),1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With some clever diagnosis of the problem we even managed to reduce the memory consumption of our model over one third! It is cruicial to know the specifics of the language you are dealing with and adjust the features according to it. Your estimator can never outperform the features you feed it with. But can you do better than this model? Try and mess with the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I hope you enjoyed reading this tutorial as much as I enjoyed writing it. You can get my current version of the tagger from my Github: https://github.com/Miksus/Syntags\n",
    "\n",
    "In case you liked my guide and you have opportunities for me, please contact me via email: koli.mikael@gmail.com"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
